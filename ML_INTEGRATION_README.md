# üêõ Lanternfly ML Integration

This document explains how the trained machine learning model has been integrated into the Lanternfly Tracker website.

## üéØ Overview

The ML integration allows the website to:
- **Automatically classify** uploaded photos as lanternflies or non-lanternflies
- **Award points** only for confirmed lanternfly sightings
- **Add locations to the map** only when lanternflies are detected
- **Provide confidence scores** for each classification

## üèóÔ∏è Architecture

```
Frontend (React) ‚Üí Backend (Node.js) ‚Üí ML Service (Python/Flask) ‚Üí Trained Model (PyTorch)
```

### Components:

1. **ML Inference Service** (`ml-model/inference/`)
   - Flask API server running on port 5001
   - Loads the trained EfficientNet-B0 model
   - Provides classification endpoints

2. **Backend ML Service** (`backend/src/services/mlService.js`)
   - Node.js service that communicates with the ML API
   - Handles fallback when ML service is unavailable
   - Manages image preprocessing and error handling

3. **Updated Photo Routes** (`backend/src/routes/photos_ml.js`)
   - Replaces mock classification with real ML predictions
   - Integrates classification results into photo upload flow
   - Updates user points and database records

## üöÄ How It Works

### Photo Upload Flow:

1. **User takes photo** in the frontend camera interface
2. **Photo is uploaded** to the backend with location data
3. **Backend calls ML service** to classify the image
4. **ML model analyzes** the image and returns:
   - `is_lantern_fly`: boolean (true/false)
   - `confidence_score`: float (0.0-1.0)
   - `points_awarded`: integer (10 for lanternfly, 0 for non-lanternfly)
5. **Backend updates database** with classification results
6. **User receives feedback**:
   - ‚úÖ "Lanternfly detected! Points awarded." (if lanternfly)
   - ‚ùå "No lanternfly detected." (if not lanternfly)
7. **Map and leaderboard** are updated accordingly

### Database Updates:

- **Photos table**: Stores classification results and confidence scores
- **Users table**: Updates total photos, confirmed lanternflies, and points
- **Map locations**: Only added for confirmed lanternfly sightings

## üìÅ File Structure

```
ml-model/
‚îú‚îÄ‚îÄ inference/
‚îÇ   ‚îú‚îÄ‚îÄ api_server.py          # Flask API server
‚îÇ   ‚îú‚îÄ‚îÄ lanternfly_classifier.py  # ML inference service
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt       # Python dependencies
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ best_model.pth         # Trained model weights
‚îÇ   ‚îî‚îÄ‚îÄ final_model.pth        # Final epoch model
‚îî‚îÄ‚îÄ scripts/
    ‚îú‚îÄ‚îÄ model_architecture.py  # Model definition
    ‚îî‚îÄ‚îÄ data_loader.py         # Data loading utilities

backend/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ mlService.js       # ML service integration
‚îÇ   ‚îî‚îÄ‚îÄ routes/
‚îÇ       ‚îî‚îÄ‚îÄ photos_ml.js       # ML-enabled photo routes
‚îî‚îÄ‚îÄ package.json               # Updated with ML dependencies
```

## üõ†Ô∏è Setup Instructions

### 1. Install ML Dependencies

```bash
cd ml-model/inference
pip install -r requirements.txt
```

### 2. Install Backend Dependencies

```bash
cd backend
npm install
```

### 3. Start the Services

#### Option A: Manual Start (Recommended for Development)

Terminal 1 - Start ML Service:
```bash
cd ml-model
python inference/api_server.py
```

Terminal 2 - Start Backend:
```bash
cd backend
npm run dev
```

Terminal 3 - Start Frontend:
```bash
cd frontend
npm run dev
```

#### Option B: Automated Start

```bash
python start_ml_integration.py
```

### 4. Test the Integration

```bash
python test_ml_integration.py
```

## üîß Configuration

### Environment Variables

Add to your `.env` file:

```env
# ML Service Configuration
ML_API_URL=http://localhost:5001

# Backend Configuration
JWT_SECRET=your-secret-key
PORT=5000
```

### Model Configuration

The ML service automatically loads the best trained model from:
- `ml-model/models/best_model.pth` (99.43% validation accuracy)

## üìä Model Performance

- **Validation Accuracy**: 99.43%
- **Test Accuracy**: 89.7%
- **ROC AUC**: 100% (Perfect discrimination)
- **Lanternfly Recall**: 100% (Catches all lanternflies)
- **Non-Lanternfly Precision**: 100% (Very reliable negative predictions)

## üß™ Testing

### Test ML Service Directly

```bash
# Health check
curl http://localhost:5001/health

# Classify an image
curl -X POST -F "image=@path/to/image.jpg" http://localhost:5001/classify
```

### Test Backend Integration

```bash
# Check ML status
curl http://localhost:5000/api/photos/ml-status

# Upload photo (requires authentication)
curl -X POST -H "Authorization: Bearer YOUR_TOKEN" \
  -F "photo=@path/to/image.jpg" \
  -F "latitude=40.7128" \
  -F "longitude=-74.0060" \
  http://localhost:5000/api/photos/upload
```

## üö® Error Handling

### ML Service Unavailable

If the ML service is down, the backend will:
1. Log the error
2. Use fallback classification (assumes non-lanternfly)
3. Continue normal operation
4. Return appropriate error messages

### Classification Failures

- Invalid image formats are rejected
- Large files (>10MB) are rejected
- Network timeouts are handled gracefully
- All errors are logged for debugging

## üìà Monitoring

### Health Endpoints

- **ML Service**: `GET /health`
- **Backend ML Status**: `GET /api/photos/ml-status`

### Logs

- ML service logs classification results
- Backend logs ML service communication
- All errors are logged with timestamps

## üîÑ Updates and Maintenance

### Updating the Model

1. Train a new model using the training scripts
2. Replace `models/best_model.pth` with the new model
3. Restart the ML service
4. Test the new model with sample images

### Scaling

For production deployment:
- Use a proper WSGI server (Gunicorn) for the ML service
- Add load balancing for multiple ML service instances
- Use Redis for caching frequent classifications
- Monitor memory usage and model loading times

## üéâ Success Metrics

The integration is working correctly when:
- ‚úÖ ML service responds to health checks
- ‚úÖ Backend can communicate with ML service
- ‚úÖ Photos are classified with reasonable confidence scores
- ‚úÖ Points are awarded only for lanternfly detections
- ‚úÖ Map locations are added only for confirmed sightings
- ‚úÖ Users receive appropriate feedback messages

## üêõ Troubleshooting

### Common Issues

1. **ML service won't start**
   - Check Python dependencies are installed
   - Verify model file exists at `models/best_model.pth`
   - Check port 5001 is available

2. **Backend can't connect to ML service**
   - Verify ML service is running on port 5001
   - Check `ML_API_URL` environment variable
   - Test with `curl http://localhost:5001/health`

3. **Classification always returns same result**
   - Check model file is not corrupted
   - Verify image preprocessing is working
   - Test with known lanternfly/non-lanternfly images

4. **High memory usage**
   - Model loads ~18MB into memory
   - Consider using smaller batch sizes
   - Monitor with `htop` or similar tools

### Debug Mode

Enable debug logging by setting:
```env
FLASK_DEBUG=1
NODE_ENV=development
```

This will provide detailed logs for troubleshooting.

---

üéØ **The ML integration is now complete and ready for production use!**
